{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9173b9a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1288\u001b[0m, in \u001b[0;36m_path_importer_cache\u001b[1;34m(cls, path)\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'C:\\\\Users\\\\trist\\\\anaconda3\\\\envs\\\\tf2.6\\\\lib\\\\site-packages\\\\tensorflow\\\\_api\\\\v2\\\\compat\\\\v2\\\\autograph'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mnist\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2.6\\lib\\site-packages\\tensorflow\\__init__.py:55\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bitwise\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compat\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2.6\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\__init__.py:39\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function \u001b[38;5;28;01mas\u001b[39;00m _print_function\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m v1\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m v2\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m forward_compatibility_horizon\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2.6\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\__init__.py:34\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bitwise\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compat\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2.6\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\compat\\__init__.py:40\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m v1\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m v2\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m forward_compatibility_horizon\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m forward_compatible\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2.6\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\compat\\v2\\__init__.py:32\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-bad-import-order\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compat\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2.6\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v2\\__init__.py:35\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m autodiff\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bitwise\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compat\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2.6\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v2\\autograph\\__init__.py:25\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function \u001b[38;5;28;01mas\u001b[39;00m _print_function\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_code\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_graph\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:982\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:925\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1349\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1318\u001b[0m, in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1290\u001b[0m, in \u001b[0;36m_path_importer_cache\u001b[1;34m(cls, path)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1266\u001b[0m, in \u001b[0;36m_path_hooks\u001b[1;34m(cls, path)\u001b[0m\n",
      "File \u001b[1;32m<frozen zipimport>:75\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, path)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:87\u001b[0m, in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import keras\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns #; sns.set_theme()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2e24956a",
   "metadata": {},
   "source": [
    "!jt -t \"onedork\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23791142",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fed4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9f73b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3, figsize = (10, 10))\n",
    "plt.gray()\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.imshow(x_train[i])\n",
    "    ax.axis('off')\n",
    "    ax.set_title('Number {}'.format(y_train[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0bd062",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33318714",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "# Each MNIST image batch is a tensor of shape (batch_size, 28, 28).\n",
    "# Each input sequence will be of size (28, 28) (height is treated like time).\n",
    "input_dim = 28\n",
    "\n",
    "units = 64\n",
    "output_size = 10  # labels are from 0 to 9\n",
    "\n",
    "# Build the RNN model\n",
    "def build_model(allow_cudnn_kernel=True):\n",
    "    # CuDNN is only available at the layer level, and not at the cell level.\n",
    "    # This means `LSTM(units)` will use the CuDNN kernel,\n",
    "    # while RNN(LSTMCell(units)) will run on non-CuDNN kernel.\n",
    "    if allow_cudnn_kernel:\n",
    "        # The LSTM layer with default options uses CuDNN.\n",
    "        lstm_layer = keras.layers.LSTM(units, input_shape=(None, input_dim))\n",
    "    else:\n",
    "        # Wrapping a LSTMCell in a RNN layer will not use CuDNN.\n",
    "        lstm_layer = keras.layers.RNN(\n",
    "            keras.layers.LSTMCell(units), input_shape=(None, input_dim)\n",
    "        )\n",
    "    model = keras.models.Sequential(\n",
    "        [\n",
    "            lstm_layer,\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Dense(output_size),\n",
    "        ]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea90f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(allow_cudnn_kernel=True)\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=\"sgd\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x_train, y_train, validation_data=(x_test, y_test), batch_size=batch_size, epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc35d60a",
   "metadata": {},
   "source": [
    "### Model Behaviors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d024545",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b461085",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.title('model train vs validation loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9102ab0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='validation')\n",
    "plt.title('model train vs validation accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4b6fbb",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f38f7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_prediction = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f27090",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pred = []\n",
    "for x in labels_prediction:\n",
    "    labels_pred.append(np.argmax(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f10c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3, figsize = (10, 10))\n",
    "plt.gray()\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.imshow(x_test[i])\n",
    "    ax.axis('off')\n",
    "    ax.set_title('Number predicted: {}'.format(labels_pred[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bd5f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy(array):\n",
    "    new_array = []\n",
    "    for i in range(len(array)):\n",
    "        new_line = [0]*len(array[i])\n",
    "        for j in range(len(array[i])):\n",
    "            new_line[j] = array[i][j]\n",
    "        new_array.append(new_line)\n",
    "    return new_array\n",
    "\n",
    "def copyLine(arr):\n",
    "    newLine = []\n",
    "    for i in range(len(arr)):\n",
    "        newLine.append(arr[i])\n",
    "    return newLine\n",
    "\n",
    "def pourcentage_ligne(matrice):\n",
    "    new_matrice = copy(matrice)\n",
    "    for i in range(len(matrice)):\n",
    "        sum_ = np.sum(matrice[i])\n",
    "        for j in range(len(matrice[i])):\n",
    "            new_matrice[i][j] = 100* matrice[i][j]/sum_\n",
    "    return new_matrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d0f8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(y_test, labels_pred)\n",
    "cf_matrix_pct_line = pourcentage_ligne(cf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd882b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,12))\n",
    "ax = sns.heatmap(cf_matrix, annot=True, fmt=\"d\", linewidth=1, cmap='Blues')\n",
    "ax.invert_yaxis()\n",
    "plt.title('Confusion Matrix\\n', fontsize = 18) \n",
    "plt.xlabel('\\nPredicted labels', fontsize = 13) \n",
    "plt.ylabel('True labels\\n', fontsize = 13) \n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15,12))\n",
    "ax = sns.heatmap(cf_matrix_pct_line, annot=True, fmt=\".2f\", linewidth=1, cmap='Blues')\n",
    "ax.invert_yaxis()\n",
    "for t in ax.texts: t.set_text(t.get_text() + \" %\")\n",
    "plt.title('Confusion Matrix - percentage per line\\n', fontsize = 18) \n",
    "plt.xlabel('\\nPredicted labels', fontsize = 13) \n",
    "plt.ylabel('True labels\\n', fontsize = 13) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8423bdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_total_err = 0\n",
    "for i in range(len(cf_matrix)):\n",
    "    for j in range(len(cf_matrix[i])):\n",
    "        if i != j:\n",
    "            nb_total_err += cf_matrix[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d08d082",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"On the validation data, there are {nb_total_err} errors, over {len(x_test)} elements\")\n",
    "print(f\"It represents a {round(nb_total_err/len(x_test), 2)} % error rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11ed43d",
   "metadata": {},
   "source": [
    "## Let's look at the mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5abe97",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_of_errors = []\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i] != labels_pred[i]:\n",
    "        indexes_of_errors.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6179af",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5, 5, figsize = (15, 15))\n",
    "plt.gray()\n",
    "for j, ax in enumerate(axs.flat):\n",
    "    i = indexes_of_errors[j]\n",
    "    ax.imshow(x_test[i])\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f'Predicted: {labels_pred[i]}, True: {y_test[i]}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166991c3",
   "metadata": {},
   "source": [
    "$ \\text{\n",
    "We're now going to take a closer look the the mistaken elements, } \\newline\n",
    "\\text{check whether the true label was the second highest probability predicted by our model}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffb412e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spot_of_true_label_in_prediction(true_label, prediction):\n",
    "    value_pred_true_label = prediction[true_label]\n",
    "    copyPrediction = copyLine(prediction)\n",
    "    copyPrediction.sort(reverse=True)\n",
    "    for i in range(len(copyPrediction)):\n",
    "        if copyPrediction[i] == value_pred_true_label:\n",
    "            return i\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6e2ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels_prediction_spots = []\n",
    "for index in indexes_of_errors:\n",
    "    prediction_spot = spot_of_true_label_in_prediction(y_test[index], labels_prediction[index])\n",
    "    true_labels_prediction_spots.append(prediction_spot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65883b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "labels, counts = np.unique(true_labels_prediction_spots, return_counts=True)\n",
    "#counts = counts / len(true_labels_prediction_spots)\n",
    "plt.bar(labels, counts, align='center', color = 'black')\n",
    "plt.gca().set_xticks(labels)\n",
    "#plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
    "plt.ylabel('Nummber of occurences\\n')\n",
    "plt.xlabel('Spot')\n",
    "plt.title('Prediction spot of true label\\n')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cdc6ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indexes_of_major_errors = []\n",
    "for i in range(len(true_labels_prediction_spots)):\n",
    "    index = indexes_of_errors[i]\n",
    "    if true_labels_prediction_spots[i] >= 3:\n",
    "        indexes_of_major_errors.append(index)\n",
    "        \n",
    "print(f\"There are {len(indexes_of_major_errors)} instances of major errors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1373d179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_second_highest_pred(pred):\n",
    "    max_, index_max = -10000, -1\n",
    "    secondMax, index_sndMax = max_-1, -1\n",
    "    for i in range(len(pred)):\n",
    "        x = pred[i]\n",
    "        if x > max_:\n",
    "            secondMax, index_sndMax = max_, index_max\n",
    "            max_, index_max = x, i\n",
    "        elif x > secondMax:\n",
    "            secondMax, index_sndMax = x, i\n",
    "            \n",
    "    return index_sndMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7424d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_per_line = 5\n",
    "\n",
    "nb_shown = 0\n",
    "while nb_shown < len(indexes_of_major_errors):\n",
    "    fig, axs = plt.subplots(1, nb_per_line, figsize=(20, 3))\n",
    "    for j in range(nb_per_line):\n",
    "        if nb_shown < len(indexes_of_major_errors):\n",
    "            i = indexes_of_errors[nb_shown]\n",
    "            axs[j].imshow(x_test[i])\n",
    "            axs[j].axis('off')\n",
    "            snd_highest = get_second_highest_pred(labels_prediction[index])\n",
    "            axs[j].set_title(f'Pred: {labels_pred[i]}, True: {y_test[i]}, 2nd Highest: {snd_highest}', fontsize=14)\n",
    "            nb_shown += 1\n",
    "        else:\n",
    "            axs[j].axis('off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
